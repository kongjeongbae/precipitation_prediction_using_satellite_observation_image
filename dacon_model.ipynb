{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def mae(y_true, y_pred) :\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return(f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    \n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def fscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
    "    return score\n",
    "\n",
    "def maeOverFscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='maeOverFscore_keras') \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재생산성을 위해 시드 고정\n",
    "SEED = 32\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator():\n",
    "    train_path = 'inputs/train/'\n",
    "    rot_path = 'inputs/rot/'\n",
    "    train_files = os.listdir(train_path)\n",
    "    rot_files = os.listdir(rot_path)\n",
    "    all_files = []\n",
    "    for i in train_files:\n",
    "        all_files.append(train_path + i)\n",
    "    for i in rot_files:\n",
    "        all_files.append(rot_path + i)\n",
    "    \n",
    "    for file in all_files:\n",
    "        npy = np.load(file)\n",
    "        if npy[:,:,-1].sum() < 0:\n",
    "            continue\n",
    "            \n",
    "        target= npy[:,:,14].reshape(40,40,1)\n",
    "        \n",
    "        terrain = (npy[:,:,9] / 100).astype('int8').reshape(40,40,1)\n",
    "        npy = np.concatenate((npy, terrain), axis=-1)\n",
    "        \n",
    "        feature = npy[:,:,[0,1,2,3,4,5,6,7,8,9,15]]\n",
    "\n",
    "        yield (feature, target)\n",
    "        \n",
    "train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([40,40,11]),tf.TensorShape([40,40,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(256).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'inputs/test'\n",
    "test_files = sorted(glob.glob(test_path + '/*'))\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for file in tqdm(test_files, desc = 'test'):\n",
    "    \n",
    "    npy = np.load(file)\n",
    "    terrain = (npy[:,:,9] / 100).astype('int8').reshape(40,40,1)\n",
    "    npy = np.concatenate((npy, terrain), axis=-1)\n",
    "    X_test.append(npy[:,:,[0,1,2,3,4,5,6,7,8,9,14]])\n",
    "                  \n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    \n",
    "    # 40 x 40 -> 20 x 20\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(pool1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 20 x 20 -> 10 x 10\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(pool2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 10 x 10 \n",
    "    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "\n",
    "    # 10 x 10 -> 20 x 20\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "\n",
    "    # 20 x 20 -> 40 x 40\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((40, 40, 11))\n",
    "output_layer = build_model(input_layer, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_history = model.fit(train_dataset, epochs = 300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "# 약 20초 걸림\n",
    "with open('D:/inputs/24/train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('D:/inputs/24/train_y.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "    train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = (train[:,:,:,9] / 100).astype('int8').reshape(len(train), 40,40,1)\n",
    "train = np.concatenate((train, terrain), axis=-1)\n",
    "train = train[:,:,:,[0,1,2,3,4,5,6,7,8,9,14]]\n",
    "score = maeOverFscore(train_y, model.predict(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('allrot300.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_dataset, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = maeOverFscore(train_y, model.predict(train))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "submission = pd.read_csv('inputs/sample_submission.csv')\n",
    "submission.iloc[:,1:] = pred.reshape(-1, 1600)\n",
    "submission.to_csv('1.374.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
