{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 및 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from custom_metric import *\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "SEED = 30\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 약 20초 걸림\n",
    "with open('D:/inputs/24/train50.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('D:/inputs/24/train_y50.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "    train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)\n",
    "\n",
    "\n",
    "with open('D:/inputs/24/test.pickle', 'rb') as f:\n",
    "    TEST = pickle.load(f)\n",
    "TEST = TEST[:, :, :, :10]    \n",
    "# 아웃라이어 수정\n",
    "# train[1,16, 24, -2] = 163.05731201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회전변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 회전변환시 마이너스(-) 하는 경우, 제곱을 해주면 target값과의 상관관계가 높아짐. 테스트해볼것!\n",
    "# v1_m_h1 = ((train[:, :, :, 0] * np.cos(np.pi / 4) - train[:, :, :, 1] * np.sin(np.pi / 4)) ** 0.5) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_m_h1 = train[:, :, :, 0] * np.cos(np.pi / 4) - train[:, :, :, 1] * np.sin(np.pi / 4)  \n",
    "v1_p_h1 = train[:, :, :, 0] * np.cos(np.pi / 4) + train[:, :, :, 1] * np.sin(np.pi / 4)  \n",
    "train[:, :, :, 0] = v1_m_h1\n",
    "train[:, :, :, 1] = v1_p_h1 \n",
    "del v1_m_h1\n",
    "del v1_p_h1\n",
    "\n",
    "v2_m_h2 = train[:, :, :, 2] * np.cos(np.pi / 4) - train[:, :, :, 3] * np.sin(np.pi / 4)\n",
    "v2_p_h2 = train[:, :, :, 2] * np.cos(np.pi / 4) + train[:, :, :, 3] * np.sin(np.pi / 4)\n",
    "train[:, :, :, 2] = v2_m_h2\n",
    "train[:, :, :, 3] = v2_p_h2 \n",
    "del v2_m_h2\n",
    "del v2_p_h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_m_h1 = TEST[:, :, :, 0] * np.cos(np.pi / 4) - TEST[:, :, :, 1] * np.sin(np.pi / 4)  \n",
    "v1_p_h1 = TEST[:, :, :, 0] * np.cos(np.pi / 4) + TEST[:, :, :, 1] * np.sin(np.pi / 4)  \n",
    "TEST[:, :, :, 0] = v1_m_h1\n",
    "TEST[:, :, :, 1] = v1_p_h1 \n",
    "del v1_m_h1\n",
    "del v1_p_h1\n",
    "\n",
    "v2_m_h2 = TEST[:, :, :, 2] * np.cos(np.pi / 4) - TEST[:, :, :, 3] * np.sin(np.pi / 4)\n",
    "v2_p_h2 = TEST[:, :, :, 2] * np.cos(np.pi / 4) + TEST[:, :, :, 3] * np.sin(np.pi / 4)\n",
    "TEST[:, :, :, 0] = v2_m_h2\n",
    "TEST[:, :, :, 1] = v2_p_h2 \n",
    "del v2_m_h2\n",
    "del v2_p_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_p_h4_30 = train[:, :, :, 5] * np.cos(np.pi / 6) + train[:, :, :, 6] * np.sin(np.pi / 6)\n",
    "v4_m_h4_30 = train[:, :, :, 5] * np.cos(np.pi / 6) - train[:, :, :, 6] * np.sin(np.pi / 6)\n",
    "train[:, :, :, 5] = v4_p_h4_30\n",
    "train[:, :, :, 6] = v4_m_h4_30\n",
    "\n",
    "v5_p_h5_30 = train[:, :, :, 7] * np.cos(np.pi / 6) + train[:, :, :, 8] * np.sin(np.pi / 6)\n",
    "v5_m_h5_30 = train[:, :, :, 7] * np.cos(np.pi / 6) - train[:, :, :, 8] * np.sin(np.pi / 6)\n",
    "train[:, :, :, 7] = v5_p_h5_30\n",
    "train[:, :, :, 8] = v5_m_h5_30\n",
    "\n",
    "del v4_p_h4_30\n",
    "del v4_m_h4_30\n",
    "del v5_p_h5_30\n",
    "del v5_m_h5_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_p_h4_30 = TEST[:, :, :, 5] * np.cos(np.pi / 6) + TEST[:, :, :, 6] * np.sin(np.pi / 6)\n",
    "v4_m_h4_30 = TEST[:, :, :, 5] * np.cos(np.pi / 6) - TEST[:, :, :, 6] * np.sin(np.pi / 6)\n",
    "TEST[:, :, :, 5] = v4_p_h4_30\n",
    "TEST[:, :, :, 6] = v4_m_h4_30\n",
    "\n",
    "v5_p_h5_30 = TEST[:, :, :, 7] * np.cos(np.pi / 6) + TEST[:, :, :, 8] * np.sin(np.pi / 6)\n",
    "v5_m_h5_30 = TEST[:, :, :, 7] * np.cos(np.pi / 6) - TEST[:, :, :, 8] * np.sin(np.pi / 6)\n",
    "TEST[:, :, :, 7] = v5_p_h5_30\n",
    "TEST[:, :, :, 8] = v5_m_h5_30\n",
    "\n",
    "del v4_p_h4_30\n",
    "del v4_m_h4_30\n",
    "del v5_p_h5_30\n",
    "del v5_m_h5_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 경도, 위도 정보 삭제함.\n",
    "train = train[:, :, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 경도, 위도 정보 삭제함.\n",
    "TEST = TEST[:, :, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate([train, train_y], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train1 = np.rot90(train, 1, (1,2))\n",
    "train2 = np.rot90(train, 2, (1,2))\n",
    "train3 = np.rot90(train, 3, (1,2))\n",
    "train_lr = np.fliplr(train)\n",
    "# train_ud = np.flipud(train)\n",
    "\n",
    "train = np.vstack([train, train1])\n",
    "del train1\n",
    "\n",
    "train = np.vstack([train, train2])\n",
    "del train2\n",
    "\n",
    "train = np.vstack([train, train3])\n",
    "del train3\n",
    "\n",
    "train = np.vstack([train, train_lr])\n",
    "del train_lr\n",
    "\n",
    "# train = np.vstack([train, train_ud])\n",
    "# del train_ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[:, :, :, -1].copy()\n",
    "train_y = train_y.reshape(train_y.shape[0], train_y.shape[1], train_y.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:,:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, train_y, test_y = train_test_split(train, train_y, test_size=0.025, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9번 channel 가공 - 카테고리형 피쳐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [  0., 100., 101., 102., 103., 105., 106., 107., 108., 109., 110.,\n",
    "#        111., 112., 113., 114., 115., 117., 118., 119., 121., 122., 123.,\n",
    "#        199., 200., 201., 202., 203., 205., 206., 207., 208., 210., 211.,\n",
    "#        212., 213., 214., 215., 217., 218., 219., 221., 222., 223., 299.,\n",
    "#        300., 301., 302., 303., 305., 306., 307., 308., 310., 311., 312.,\n",
    "#        313., 314., 315., 317., 318., 319., 321., 322.]\n",
    "# train = np.delete(train, 9, axis=3)\n",
    "# test = np.delete(test, 9, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from features import terrain\n",
    "\n",
    "# train, test = terrain(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_np로 결합 후 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ss 약 5분 걸림\n",
    "# from preprocessing import scaling\n",
    "\n",
    "# train, test = scaling(train, test, 'ss') # 3번째 인자 'rs', 'ms', 'ss' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선언 - Unet, Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_model, build_model2\n",
    "from tensorflow.keras.layers import Input, Conv2D, Add, BatchNormalization, concatenate\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input((40, 40, train.shape[3]))\n",
    "output_layer = build_model(input_layer, 32)\n",
    "\n",
    "# sgd = tf.keras.optimizers.SGD(0.01)\n",
    "# stocastic_avg_opt = tfa.optimizers.SWA(sgd)\n",
    "\n",
    "# ad = tf.keras.optimizers.Adam(0.01)\n",
    "# stocastic_avg_opt = tfa.optimizers.SWA(ad)\n",
    "# model.compile(loss=\"mae\", optimizer=stocastic_avg_opt, metrics=[\"mae\"])\n",
    "#\n",
    "\n",
    "\n",
    "# model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model():\n",
    "    inputs=Input(x_train.shape[1:])\n",
    "    \n",
    "    bn=BatchNormalization()(inputs)\n",
    "    conv0=Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
    "    \n",
    "    bn=BatchNormalization()(conv0)\n",
    "    conv=Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    concat=concatenate([conv0, conv], axis=3)\n",
    "    \n",
    "    bn=BatchNormalization()(concat)\n",
    "    conv=Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
    "    concat=concatenate([concat, conv], axis=3)\n",
    "        \n",
    "    for i in range(5):\n",
    "        bn=BatchNormalization()(concat)\n",
    "        conv=Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
    "        concat=concatenate([concat, conv], axis=3)\n",
    "    \n",
    "    bn=BatchNormalization()(concat)\n",
    "    outputs=Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
    "    \n",
    "    model=Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('epochs_8.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for train_idx in k_fold.split(train):\n",
    "    indexes.append(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 로드해서 잘 복원되는지 확인해볼것.\n",
    "# import pickle\n",
    "# with open('submissions/22_23_kfold_index.pickle', 'wb') as f:\n",
    "#     pickle.dump(indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "indexes[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold 모델 훈련 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FOLD = 4\n",
    "k_fold = KFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "EPOCHS = 60\n",
    "history = []\n",
    "scores = []\n",
    "\n",
    "result = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_number = 0\n",
    "for train_idx, val_idx in k_fold.split(train, train_y):\n",
    "\n",
    "    x_train, y_train = train[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train[val_idx], train_y[val_idx]\n",
    "    \n",
    "#     model = Model(input_layer, output_layer)\n",
    "    model = resnet_model()\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    \n",
    "    es = EarlyStopping(patience=6, verbose=1)\n",
    "    mc = ModelCheckpoint(f'best_{model_number}.h5', save_best_only=True, verbose=1)\n",
    "    rlp = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.8)\n",
    "    csv_logger = CSVLogger(f'training_{model_number}.csv')\n",
    "    \n",
    "    model_ = model.fit(x_train, np.log(y_train+1), epochs = EPOCHS, validation_data=(x_val, np.log(y_val+1)), verbose=1, batch_size = 64, callbacks = [es, mc, rlp, csv_logger])\n",
    "        \n",
    "        \n",
    "    score = maeOverFscore(y_val, np.exp(model.predict(x_val))-1)\n",
    "    print('mae / fscore: ' + str(score) + '\\n')\n",
    "    scores.append(score)\n",
    "    print(scores)\n",
    "    \n",
    "    history.append(model_)\n",
    "    model.load_weights(f'best_{model_number}.h5')\n",
    "    result += model.predict(TEST) / FOLD\n",
    "    model_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(history[0].history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자체 test셋으로 검증\n",
    "리더보드와 매우 비슷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('inputs/my_test_set.pickle', 'rb') as f:\n",
    "#     test, test_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = 0\n",
    "tmp = 0\n",
    "for i in range(4):\n",
    "    model = resnet_model()\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.load_weights(f'best_{i}.h5')\n",
    "    tmp += model.predict(test) / 4\n",
    "    \n",
    "model_score = maeOverFscore(test_y, tmp)\n",
    "model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 0\n",
    "for i in range(4):\n",
    "    model = resnet_model()\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.load_weights(f'best_{i}.h5')\n",
    "    result += model.predict(TEST)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('inputs/sample_submission.csv')\n",
    "submission.iloc[:,1:] = result.reshape(-1, 1600)\n",
    "submission.to_csv('kfold_resnet_4_rot.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "tmp1 = pd.read_csv('22_unet_1.csv')\n",
    "tmp2 = pd.read_csv('23_kfold_resnet_4.csv')\n",
    "\n",
    "tmp1.iloc[:, 1:] = (tmp1.iloc[:, 1:] * 0.5) + (tmp2.iloc[:, 1:] * 0.5)\n",
    "\n",
    "tmp1.to_csv('ensemble_22_23.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해야할 일\n",
    "\n",
    "1. ~~스케일링(Scaling) - Robust, log, Standard Scaler  ~~  \n",
    "스케일링 방법을 다르게 해야하나. 하나의 사진을 기준으로 처리해야 할지 아니면 1번픽셀, 2번픽셀... 1600픽셀 끼리 해야하나\n",
    "2. ~~위도 경도 피쳐를 가지고 위도+경도, 위도-경도 피쳐 만들기(45도 회전변환)~~: 30, 60도 변환 추가\n",
    "3. 현재 custom metric이 작동하지 않으므로, 이 또한 수정해야함.\n",
    "4. tree모델 만들고, 앙상블\n",
    "5. ~~target 값에 log 취하기~~: 점수 안오름\n",
    "6. 순서가 바뀌긴 했으나, EDA 작업하자.\n",
    "7. 강수량 타일이 10개 미만인 것의 평균, 20개미만의 평균.... 50개 미만의 평균... 알아보자\n",
    "8. ~~augumentation 사용해서 강수량이 일정수준 이상인 사진 augementation 하자~~ - 다만, regression인 만큼 가장자리 어떻게 처리할지 생각해보자. - 정사각형 사진이기에 90도 돌린사진, 180도 돌린사진, 270도 돌린사진 이렇게만 해도 데이터가 증식될거같음 -  \n",
    "**그런데!!!!!** 생각해봐야할것이.....  \n",
    "위도, 경도 등 여러 요소가 존재할텐데 돌려버리면 원래는 비 안오는거를 비온다고 볼 수도 있을 듯 싶다. 쉽게 예를 들면 I 모양일때는 비가 오고, ㅡ 모양일때는 비가안오는데, 돌리는 바람에 안오는걸 온다고 할 수도 있을 것 같다. - 이건 테스트해볼수밖에 없을 듯 싶다.  \n",
    "돌릴수있는방법도 여러가지이다. 90도씩회전하기, 수직축기준으로 전환, 수평축기준으로 전환 등 - 캐글에서는 수직축, 수평축으로 전환해서 augmentation 썼다고 함.  위성이 도는 방향을 보면, 270도 돌리는 것도 괜찮을듯\n",
    "9. pretrained 모델 활용방안 생각하기 - 최소 사진크기가 존재하는데 우리는 40x40이라 작은편.. 이걸 40x40을 이어 붙여서 200x200으로 만들어서 넣으면 될거같은데 시도해보자.\n",
    "10. 9번채널 카테고리 변수 원핫인코딩\n",
    "11. Unet 모델과 FPN 모델 앙상블해서 제출하자\n",
    "12. loss='mse', metric=['mse', 'mae'] 이렇게 해보자\n",
    "13. U_res_net 구현하기\n",
    "14. 회전변환한 걸로 U_net 돌려서 제출하기\n",
    "15. off nadir viewing angle, earth incidence angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 리더보드(5부터) | mae / fscore | mae | 비고 |\n",
    "|---|:---:|---:|---:|\n",
    "| 1.93737 | 1.8744 | 0.2451 |  |\n",
    "| 1.75177 | 1.7016 | 0.2384 |  |\n",
    "| 1.61793 | 1.4234 | 0.0832 | 리더보드랑 metric 점수랑 차이 많이 남. 해결해야함. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
