{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import random\n",
    "from custom_metric import *\n",
    "\n",
    "SEED = 30\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "with open('D:/inputs/24/train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('D:/inputs/24/train_y.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "    train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)\n",
    "with open('D:/inputs/24/test.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "    \n",
    "LEN_TRAIN = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.delete(train, [0,1,2,3,4,5,6], axis = 0) # 200x200으로 맞추기 위해서. 7개 날림.\n",
    "train = train.reshape(75950 // (5*5), 200, 200, 14) \n",
    "\n",
    "train_y = np.delete(train_y, [0,1,2,3,4,5,6], axis = 0)\n",
    "train_y = train_y.reshape(75950 // (5*5), 200, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D, SeparableConv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_layer):\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, padding='same', name='block1_conv1')(input_layer)\n",
    "    x = layers.BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),  padding='same', use_bias=False, name='block1_conv2')(x)\n",
    "    x = layers.BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = layers.Conv2D(128, (1, 1),strides=(2, 2),padding='same',use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization()(residual)\n",
    "\n",
    "    x = layers.SeparableConv2D(128, (3, 3),padding='same',use_bias=False,name='block2_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(128, (3, 3),padding='same',use_bias=False,name='block2_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),strides=(2, 2), padding='same',name='block2_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "\n",
    "    for i in range(8):\n",
    "        residual = x\n",
    "        prefix = 'block' + str(i + 5)\n",
    "\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "        x = layers.SeparableConv2D(128, (3, 3), padding='same', use_bias=False,name=prefix + '_sepconv1')(x)\n",
    "        x = layers.BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "        x = layers.SeparableConv2D(128, (3, 3), padding='same',use_bias=False,name=prefix + '_sepconv2')(x)\n",
    "        x = layers.BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "        x = layers.SeparableConv2D(128, (3, 3), padding='same',use_bias=False,name=prefix + '_sepconv3')(x)\n",
    "        x = layers.BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization()(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block13_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),padding='same',use_bias=False,name='block13_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(name='block13_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block13_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(1024, (3, 3),padding='same',use_bias=False,name='block13_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(name='block13_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),strides=(2, 2),padding='same',name='block13_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = layers.SeparableConv2D(1536, (3, 3),padding='same',use_bias=False,name='block14_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(name='block14_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv1_act')(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(2048, (3, 3),padding='same',use_bias=False,name='block14_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "    x = Conv2D(1, (1,1), padding=\"same\", activation='relu')(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "    return x\n",
    "    \n",
    "input_layer = Input((200, 200, 14))\n",
    "output_layer = build_model(input_layer)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "scores = []\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def build_model(input_layer, start_neurons):\n",
    "    \n",
    "    # 40 x 40 -> 20 x 20\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(pool1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 20 x 20 -> 10 x 10\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(pool2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 10 x 10 \n",
    "    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "\n",
    "    # 10 x 10 -> 20 x 20\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "\n",
    "    # 20 x 20 -> 40 x 40\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((40, 40, train.shape[3]))\n",
    "output_layer = build_model(input_layer, 32)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "scores = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras]) # custom metric으로 하면 실행이 안됨\n",
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(train, train_y, batch_size = 100, epochs = 1)\n",
    "\n",
    "# model.predict(test2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
