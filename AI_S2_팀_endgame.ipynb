{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Nj76qUe2lnA"
   },
   "source": [
    "## [Dacon] AI프렌즈 시즌2 강수량 산출 경진대회\n",
    "## 팀: endgame\n",
    "## 2020년 월 일 (제출날짜)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <div style=\"color:red\">README</div>\n",
    "- 하드웨어 리소스가 많이 소요되는 코드입니다. 제 컴퓨터의 램이 128GB라서 모든 데이터를 램에 올려놓고 작업을 실시했습니다.\n",
    "- 저 같은 경우, EDA, 모델링 각각 다른 ipynb 파일에서 작업을 진행했는데, 제출용 파일이다보니 모든 코드를 한 곳에 모아 실행하기에 메모리가 부족할 가능성이 커질 것 같습니다.\n",
    "- train.zip, test.zip 파일은 각각 data/train, data/test 폴더에 압축을 해제해주세요.\n",
    "- sample_submission.csv는 data 폴더에 위치시켜 주세요.\n",
    "\n",
    "<div style=\"color:red\">혹시 위의 글을 안 읽으셨다면 꼭 읽어주세요!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYHb_Mf-2lnG"
   },
   "source": [
    "## 1. 라이브러리 및 데이터 (Library & Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtKnyRor2lnI"
   },
   "outputs": [],
   "source": [
    "# 파일관리 및 파일선택\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from custom_metric import *\n",
    "\n",
    "SEED = 30\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zjQY_KY2lnR"
   },
   "source": [
    "## 2. 데이터 전처리 (Data Cleansing & Pre-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 데이터셋을 만들고 pickle로 저장\n",
    "- -9999와 같은 missing value가 들어있으면 제거\n",
    "- 0.1 이상 내린 픽셀이 UPPER 값 이상인 사진만 데이터셋에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "colab": {},
    "colab_type": "code",
    "id": "pb0OD3v82lnT"
   },
   "outputs": [],
   "source": [
    "dir_train = 'data/train/'\n",
    "dir_test = 'data/test/'\n",
    "UPPER = 50\n",
    "\n",
    "def make_dataset(dir_train, dir_test, UPPER):\n",
    "    # train dataset\n",
    "    train = []\n",
    "    train_y = []\n",
    "\n",
    "    for i in os.listdir(dir_train):\n",
    "        npy = np.load(dir_train + i)\n",
    "\n",
    "        # missing value 제거\n",
    "        if npy[:, :, -1].sum() < 0:\n",
    "            continue\n",
    "        \n",
    "        # 0.1이상 내린 픽셀이 UPPER 값 이상인 사진만\n",
    "        if (npy[:, :, -1] >= 0.1).sum() >= UPPER:\n",
    "            train.append(npy[:, :, :-1])\n",
    "            train_y.append(npy[:, :, -1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    with open(f'data/train{UPPER}.pickle', 'wb') as f:\n",
    "        pickle.dump(train, f, protocol=4)\n",
    "\n",
    "    with open(f'data/train_y{UPPER}.pickle', 'wb') as f:\n",
    "        pickle.dump(train_y, f, protocol=4)\n",
    "\n",
    "    del train\n",
    "    del train_y\n",
    "\n",
    "    # test dataset\n",
    "    test = []\n",
    "\n",
    "    for i in os.listdir(dir_test):\n",
    "        npy = np.load(dir_test + i)\n",
    "        test.append(npy)\n",
    "    test = np.array(test)\n",
    "\n",
    "    with open('data/test.pickle', 'wb') as f:\n",
    "        pickle.dump(test, f, protocol=4)\n",
    "    del test\n",
    "    \n",
    "make_dataset(dir_train, dir_test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 pickle 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train50.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "# 0~9번채널만 사용\n",
    "train = train[:, :, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_y50.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)\n",
    "\n",
    "train_y = np.log(train_y+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.pickle', 'rb') as f:\n",
    "    TEST = pickle.load(f)\n",
    "TEST = TEST[:, :, :, :10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwLtCHGC2lnb"
   },
   "source": [
    "## 3. 탐색적 자료분석 (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BliMtn4E2lnd"
   },
   "source": [
    "### 3.1 시각화를 이용한 EDA\n",
    "- v별, h별 합계 피쳐를 만들고 강수량과의 관계를 시각적으로 파악해봤습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir = os.listdir('inputs/train/')\n",
    "image_sample = np.load(f'inputs/train/{image_dir[random.randrange(len(image_dir))]}')\n",
    "\n",
    "def showimg(img):\n",
    "    ch15_v = 0\n",
    "    for i in [0,2,4,5,7]:\n",
    "        ch15_v += img[:,:,i]\n",
    "    ch15_h = 0\n",
    "    for i in [1,3,6,8]:\n",
    "        ch15_h += img[:,:,i]\n",
    "    ch15_v = ch15_v.reshape(40,40,1)\n",
    "    ch15_h = ch15_h.reshape(40,40,1)\n",
    "    img = np.concatenate([img, ch15_v], -1)\n",
    "    img = np.concatenate([img, ch15_h], -1)\n",
    "    return img\n",
    "\n",
    "image_sample = showimg(image_sample)\n",
    "\n",
    "color_map = plt.cm.get_cmap('RdBu')\n",
    "color_map = color_map.reversed()\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(2,6,i+1)\n",
    "    plt.imshow(image_sample[:, :, i], cmap=color_map)\n",
    "    plt.title(f'ch_{i}', fontdict= {'fontsize': 16})\n",
    "\n",
    "plt.subplot(2,6,10)\n",
    "plt.imshow(image_sample[:,:,-3], cmap = color_map)\n",
    "plt.title('rain', fontdict= {'fontsize': 16})\n",
    "\n",
    "plt.subplot(2,6,11)\n",
    "plt.imshow(image_sample[:,:,-2], cmap = color_map)\n",
    "plt.title('v_sum', fontdict= {'fontsize': 16})\n",
    "\n",
    "plt.subplot(2,6,12)\n",
    "plt.imshow(image_sample[:,:,-1], cmap = color_map)\n",
    "plt.title('h_sum', fontdict= {'fontsize': 16})\n",
    "\n",
    "plt.subplots_adjust(top=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 상관관계를 이용한 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qyq90ZzB2lnk"
   },
   "source": [
    "## 4. 변수 선택 및 모델 구축 (Feature Engineering & Initial Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 vertical, horizontal 별로 Sum한 피쳐 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rel1AkRP2lnm"
   },
   "outputs": [],
   "source": [
    "def channel_sum(data):\n",
    "    data_v = data[:, :, :, 0].copy() + data[:, :, :, 2].copy() + data[:, :, :, 4].copy() + data[:, :, :, 5].copy() +data[:, :, :, 7].copy()\n",
    "    data_h = data[:, :, :, 1].copy() + data[:, :, :, 3].copy() + data[:, :, :, 6].copy() + data[:, :, :, 8].copy()\n",
    "\n",
    "    data_v = data_v.reshape(data_v.shape[0], data_v.shape[1], data_v.shape[2], 1)\n",
    "    data_h = data_h.reshape(data_h.shape[0], data_h.shape[1], data_h.shape[2], 1)\n",
    "\n",
    "    data = np.concatenate([data, data_v.copy()], -1)\n",
    "    data = np.concatenate([data, data_h.copy()], -1)\n",
    "\n",
    "    return data\n",
    "\n",
    "train = channel_sum(train)\n",
    "TEST = channel_sum(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 9번 채널 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:, :, :, 9] = train[:, :, :, 9] / 322\n",
    "TEST[:, :, :, 9] = TEST[:, :, :, 9] / 322\n",
    "VAL_X[:, :, :, 9] = VAL_X[:, :, :, 9] / 322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V21KUtyl2lnu"
   },
   "source": [
    "## 5. 모델 학습 및 검증 (Model Tuning & Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNU-ahud2lnv"
   },
   "source": [
    "### 5.1 모델 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model(shape):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv0 = Conv2D(256, kernel_size=1, strides=1, padding='same',\n",
    "                   activation='relu', kernel_initializer='he_normal')(bn)\n",
    "\n",
    "    bn = BatchNormalization()(conv0)\n",
    "    conv = Conv2D(128, kernel_size=2, strides=1, padding='same',\n",
    "                  activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    concat = concatenate([conv0, conv], axis=3)\n",
    "\n",
    "    bn = BatchNormalization()(concat)\n",
    "    conv = Conv2D(64, kernel_size=3, strides=1, padding='same',\n",
    "                  activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    concat = concatenate([concat, conv], axis=3)\n",
    "\n",
    "    for i in range(9):\n",
    "        bn = BatchNormalization()(concat)\n",
    "        conv = Conv2D(32, kernel_size=3, strides=1, padding='same',\n",
    "                      activation='relu', kernel_initializer='he_normal')(bn)\n",
    "        concat = concatenate([concat, conv], axis=3)\n",
    "\n",
    "    bn = BatchNormalization()(concat)\n",
    "    outputs = Conv2D(1, kernel_size=1, strides=1, padding='same',\n",
    "                     activation='relu', kernel_initializer='he_normal')(bn)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = resnet_model(train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 모델 2 - inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(shape_, LOOP):\n",
    "    \n",
    "    input_ = Input(shape=shape_)\n",
    "    activation_ = 'relu'\n",
    "    \n",
    "    bn = BatchNormalization()(input_)\n",
    "    conv0 = Conv2D(256, kernel_size=1, strides=1, padding='same',\n",
    "                   activation=activation_, kernel_initializer='he_normal')(bn)\n",
    "    bn = BatchNormalization()(conv0)\n",
    "    conv = Conv2D(128, kernel_size=2, strides=1, padding='same',\n",
    "                  activation=activation_, kernel_initializer='he_normal')(bn)\n",
    "    concat = concatenate([conv0, conv], axis=3)\n",
    "\n",
    "    bn = BatchNormalization()(concat)\n",
    "    conv = Conv2D(64, kernel_size=3, strides=1, padding='same',\n",
    "                  activation=activation_, kernel_initializer='he_normal')(bn)\n",
    "    concat = concatenate([concat, conv], axis=3)\n",
    "    \n",
    "    for i in range(LOOP):\n",
    "        bn = BatchNormalization()(concat)\n",
    "        x_1 = Conv2D(32, 1, padding='same', activation=activation_)(bn)\n",
    "\n",
    "        x_2 = Conv2D(32, 1, padding='same', activation=activation_)(bn)\n",
    "        x_2 = Conv2D(32, 3, padding='same', activation=activation_)(x_2)\n",
    "\n",
    "        x_3 = Conv2D(32, 1, padding='same', activation=activation_)(bn)\n",
    "        x_3 = Conv2D(32, 3, padding='same', activation=activation_)(x_3)\n",
    "        x_3 = Conv2D(32, 3, padding='same', activation=activation_)(x_3)\n",
    "\n",
    "        x_4 = AveragePooling2D(\n",
    "            pool_size=(3, 3), strides=1, padding='same')(bn)\n",
    "        x_4 = Conv2D(32, 1, padding='same', activation=activation_)(x_4)\n",
    "\n",
    "        concat = concatenate([x_1, x_2, x_3, x_4])\n",
    "    \n",
    "    bn = BatchNormalization()(concat)\n",
    "\n",
    "    outputs = Conv2D(1, kernel_size=1, strides=1, padding='same',\n",
    "                     activation=activation_, kernel_initializer='he_normal')(bn)\n",
    "\n",
    "    model = Model(inputs=input_, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "model = inception(train.shape[1:] , 5) # inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 모델 3 - deep inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception(train.shape[1:] , 7) # loop문을 7번으로 증가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_resnet = pd.read_csv('46kfold_unet1.csv')\n",
    "result_inception = pd.read_csv('44kfold_unet.csv')\n",
    "result_deep_inception = pd.read_csv('last.csv')\n",
    "\n",
    "result_resnet.iloc[:, 1:] = (result_resnet.iloc[:, 1:] * 0.25) + (result_inception.iloc[:, 1:] * 0.25) + (result_deep_inception.iloc[:, 1:] * 0.5)\n",
    "\n",
    "result_resnet.to_csv('endgame_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BNtFKiZ2ln6"
   },
   "source": [
    "## 6. 결과 및 결언 (Conclusion & Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMEdF_8z2ln7"
   },
   "source": [
    "- 모델이 오버피팅 되는 경우는 적었음. 이에 모델의 layer를 깊게 쌓아 점수가 향상됨.\n",
    "- 레스넷 모델의 경우, augmentation을 적게 했는데, 더 많은 데이터를 바탕으로 모델을 돌리면 점수가 향상되고, 이를 앙상블하면 더 좋은 점수를 기대할 수 있을 것 같다.\n",
    "- 대회를 준비하신 모든 분들, 대회에 참여하신 모든 분들 고생많았습니다.\n",
    "- 마지막으로 Gold 님께 감사하다는 말을 전하고 싶습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_S2_코드양식.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
