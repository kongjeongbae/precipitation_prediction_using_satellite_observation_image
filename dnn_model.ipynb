{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 및 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from custom_metric import *\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "SEED = 30\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 약 20초 걸림\n",
    "with open('D:/inputs/24/train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('D:/inputs/24/train_y.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "    train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)\n",
    "\n",
    "\n",
    "with open('D:/inputs/24/test.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# 아웃라이어 수정\n",
    "train[1,16, 24, -2] = 163.05731201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentation 불러오기 및 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/inputs/24/rot_train180.pickle', 'rb') as f:\n",
    "    rot_train180 = pickle.load(f)\n",
    "    \n",
    "with open('D:/inputs/24/rot_train180_y.pickle', 'rb') as f:\n",
    "    rot_train180_y = pickle.load(f)\n",
    "    rot_train180_y = rot_train180_y.reshape(rot_train90y.shape[0], 40, 40, 1)\n",
    "\n",
    "train = np.vstack([train, rot_train180])\n",
    "train_y = np.vstack([train_y, rot_train180_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/inputs/24/rot_train270.pickle', 'rb') as f:\n",
    "    rot_train270 = pickle.load(f)\n",
    "    \n",
    "with open('D:/inputs/24/rot_train270_y.pickle', 'rb') as f:\n",
    "    rot_train270y = pickle.load(f)\n",
    "    rot_train270y = rot_train270y.reshape(rot_train270y.shape[0], 40, 40, 1)\n",
    "\n",
    "train = np.vstack([train, rot_train270])\n",
    "train_y = np.vstack([train_y, rot_train270y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    train.shape,\n",
    "    train_y.shape,\n",
    "    test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건에 맞는 사진 개수 세는 알고리즘.\n",
    "# from tqdm import tqdm\n",
    "# cnt = 0\n",
    "# for i in tqdm(train_y):\n",
    "#     for ii in i:\n",
    "#         if (ii == 0).sum() != 40:\n",
    "#             cnt += 1\n",
    "# cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_np로 결합 후 회전변환 피쳐 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약 3분 걸림\n",
    "from features import rotation\n",
    "\n",
    "train, test = rotation(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9번 channel 가공 - 카테고리형 피쳐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [  0., 100., 101., 102., 103., 105., 106., 107., 108., 109., 110.,\n",
    "#        111., 112., 113., 114., 115., 117., 118., 119., 121., 122., 123.,\n",
    "#        199., 200., 201., 202., 203., 205., 206., 207., 208., 210., 211.,\n",
    "#        212., 213., 214., 215., 217., 218., 219., 221., 222., 223., 299.,\n",
    "#        300., 301., 302., 303., 305., 306., 307., 308., 310., 311., 312.,\n",
    "#        313., 314., 315., 317., 318., 319., 321., 322.]\n",
    "# train = np.delete(train, 9, axis=3)\n",
    "# test = np.delete(test, 9, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import terrain\n",
    "\n",
    "train, test = terrain(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_np로 결합 후 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ss 약 5분 걸림\n",
    "from preprocessing import scaling\n",
    "\n",
    "train, test = scaling(train, test, 'ss') # 3번째 인자 'rs', 'ms', 'ss' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.save('D:/inputs/24/ss_train_rotsum.npy', train)\n",
    "np.save('D:/inputs/24/ss_test_rotsum.npy', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = np.load('D:/inputs/24/ss_train_rotsum.npy')\n",
    "test = np.load('D:/inputs/24/ss_test_rotsum.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/inputs/24/train_y.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "    train_y = train_y.reshape(train_y.shape[0], 40, 40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_model, build_model2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "input_layer = Input((40, 40, train.shape[3]))\n",
    "output_layer = build_model(input_layer, 32)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# sgd = tf.keras.optimizers.SGD(0.01)\n",
    "# stocastic_avg_opt = tfa.optimizers.SWA(sgd)\n",
    "\n",
    "# ad = tf.keras.optimizers.Adam(0.01)\n",
    "# stocastic_avg_opt = tfa.optimizers.SWA(ad)\n",
    "# model.compile(loss=\"mae\", optimizer=stocastic_avg_opt, metrics=[\"mae\"])\n",
    "#\n",
    "\n",
    "\n",
    "# model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('epochs_8.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "for _ in range(5):\n",
    "    for i in range(EPOCHS):\n",
    "        print(f\"epochs: {i+1}\")\n",
    "        model_history = model.fit(train, train_y, epochs = 1, verbose=1, batch_size = 200)\n",
    "    score = maeOverFscore(train_y, model.predict(train))\n",
    "    print('mae / fscore: ' + str(score) + '\\n')\n",
    "    scores.append(score)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "for _ in range(5):\n",
    "    for i in range(EPOCHS):\n",
    "        print(f\"epochs: {i+1}\")\n",
    "        model_history = model.fit(train, train_y, epochs = 1, verbose=1, batch_size = 200)\n",
    "    score = maeOverFscore(train_y, model.predict(train))\n",
    "    print('mae / fscore: ' + str(score) + '\\n')\n",
    "    scores.append(score)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(train, train_y, shuffle=True, random_state=0):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = train_y[train_index], train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mae loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 및 submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rot480.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model.save('epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "submission = pd.read_csv('inputs/sample_submission.csv')\n",
    "submission.iloc[:,1:] = pred.reshape(-1, 1600)\n",
    "submission.to_csv('nodropout_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해야할 일\n",
    "\n",
    "1. ~~스케일링(Scaling) - Robust, log, Standard Scaler  ~~  \n",
    "스케일링 방법을 다르게 해야하나. 하나의 사진을 기준으로 처리해야 할지 아니면 1번픽셀, 2번픽셀... 1600픽셀 끼리 해야하나\n",
    "2. ~~위도 경도 피쳐를 가지고 위도+경도, 위도-경도 피쳐 만들기(45도 회전변환)~~: 30, 60도 변환 추가\n",
    "3. 현재 custom metric이 작동하지 않으므로, 이 또한 수정해야함.\n",
    "4. tree모델 만들고, 앙상블\n",
    "5. ~~target 값에 log 취하기~~: 점수 안오름\n",
    "6. 순서가 바뀌긴 했으나, EDA 작업하자.\n",
    "7. 강수량 타일이 10개 미만인 것의 평균, 20개미만의 평균.... 50개 미만의 평균... 알아보자\n",
    "8. ~~augumentation 사용해서 강수량이 일정수준 이상인 사진 augementation 하자~~ - 다만, regression인 만큼 가장자리 어떻게 처리할지 생각해보자. - 정사각형 사진이기에 90도 돌린사진, 180도 돌린사진, 270도 돌린사진 이렇게만 해도 데이터가 증식될거같음 -  \n",
    "**그런데!!!!!** 생각해봐야할것이.....  \n",
    "위도, 경도 등 여러 요소가 존재할텐데 돌려버리면 원래는 비 안오는거를 비온다고 볼 수도 있을 듯 싶다. 쉽게 예를 들면 I 모양일때는 비가 오고, ㅡ 모양일때는 비가안오는데, 돌리는 바람에 안오는걸 온다고 할 수도 있을 것 같다. - 이건 테스트해볼수밖에 없을 듯 싶다.  \n",
    "돌릴수있는방법도 여러가지이다. 90도씩회전하기, 수직축기준으로 전환, 수평축기준으로 전환 등 - 캐글에서는 수직축, 수평축으로 전환해서 augmentation 썼다고 함.  위성이 도는 방향을 보면, 270도 돌리는 것도 괜찮을듯\n",
    "9. pretrained 모델 활용방안 생각하기 - 최소 사진크기가 존재하는데 우리는 40x40이라 작은편.. 이걸 40x40을 이어 붙여서 200x200으로 만들어서 넣으면 될거같은데 시도해보자.\n",
    "10. 9번채널 카테고리 변수 원핫인코딩\n",
    "11. Unet 모델과 FPN 모델 앙상블해서 제출하자\n",
    "12. loss='mse', metric=['mse', 'mae'] 이렇게 해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 리더보드(5부터) | mae / fscore | mae | 비고 |\n",
    "|---|:---:|---:|---:|\n",
    "| 1.93737 | 1.8744 | 0.2451 |  |\n",
    "| 1.75177 | 1.7016 | 0.2384 |  |\n",
    "| 1.61793 | 1.4234 | 0.0832 | 리더보드랑 metric 점수랑 차이 많이 남. 해결해야함. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
